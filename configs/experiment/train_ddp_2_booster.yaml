# @package _global_

# to execute this experiment run:
# python train.py experiment=train_ddp; it will collect the parameters from the default files specified below, 
# and override certain parameters as shown below for trainer and data classes

#default files used to set up the parameters; you can change the .yaml file if you want to use another file as default;
# e.g. if you want to use tensorboard instaed of wandb as a logger, please change the line 13 to tensorboard.yaml
defaults:
  - override /data: oneprot.yaml
  - override /model: oneprot_2.yaml
  - override /callbacks: default.yaml
  - override /logger: wandb.yaml
  - override /trainer: ddp.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ['pocket','struct','text','msa', "facebook/esm2_t36_3B_UR50D"]
#tags: ['msa', "facebook/esm2_t36_3B_UR50D"]


seed: 12345

# overriding certain classes; you can also override other classes (e.g. model, callbacks etc.)

trainer:
  min_epochs: 1
  max_epochs: 46
  #max_steps: 10
  num_nodes: 8
  #precision: 16
  #gradient_clip_val: 1.0
  num_sanity_val_steps: 0
  val_check_interval: 26
  strategy: 'ddp_find_unused_parameters_true'

data:
  data_modalities: ['pocket','struct','text','msa']
  #data_modalities: ['msa']
  seq_tokenizer: "facebook/esm2_t33_650M_UR50D"
  text_tokenizer: microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext
  batch_size: 64

ckpt_path: '/p/project/hai_oneprot/bazarova1/oneprot/logs/train/runs/2024-04-28_21-36-50/checkpoints/epoch_038_pocket_struct_text_msa.ckpt' #/p/project/hai_oneprot/bazarova1/oneprot/logs/train/runs/2024-04-26_01-01-07/checkpoints/last-v1.ckpt

callbacks:
  model_checkpoint:
    filename: "epoch_{epoch:03d}_pocket_struct_text_msa"