# @package _global_

# to execute this experiment run:
# python train.py experiment=train_ddp; it will collect the parameters from the default files specified below, 
# and override certain parameters as shown below for trainer and data classes

#default files used to set up the parameters; you can change the .yaml file if you want to use another file as default;
# e.g. if you want to use tensorboard instaed of wandb as a logger, please change the line 13 to tensorboard.yaml
defaults:
  - override /data: oneprot.yaml
  - override /model: oneprot_2.yaml
  - override /callbacks: default.yaml
  - override /logger: wandb.yaml
  - override /trainer: ddp.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ['struct', "facebook/esm2_t36_3B_UR50D"]
#tags: ['msa', "facebook/esm2_t36_3B_UR50D"]


seed: 12345

# overriding certain classes; you can also override other classes (e.g. model, callbacks etc.)

trainer:
  min_epochs: 1
  max_epochs: 2
  #max_steps: 10
  num_nodes: 8
  #precision: 16
  #gradient_clip_val: 1.0
  num_sanity_val_steps: 0
  val_check_interval: 30
  strategy: 'ddp_find_unused_parameters_true'

data:
  data_modalities: ['struct']
  #data_modalities: ['msa']
  seq_tokenizer: "facebook/esm2_t33_650M_UR50D"
  text_tokenizer: microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext
  batch_size: 64
  seqsim: '40ss'
  #pocket_data_type: "lmdb"

#ckpt_path: '/p/project/hai_oneprot/bazarova1/oneprot-main/logs/train/runs/2024-05-30_21-48-47/checkpoints/last.ckpt'  #'/p/project/hai_oneprot/vanderweg1/oneprot/logs/train/runs/2024-05-25_03-58-51/checkpoints/epoch_005_pocket.ckpt'

callbacks:
  model_checkpoint:
    filename: "epoch_{epoch:03d}_struct"