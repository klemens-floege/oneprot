# flexiblemlp_config.yaml

defaults:
  - _self_
  - override hydra/sweeper: basic

evaluate_on: ["train", "valid", "test"]
emb_dir: /path/to/output_dir/embeddings/
results_dir: /path/to/output_dir/results/

# Model configuration
model:
  input_dim: 1280  # Adjust based on your embedding size
  hidden_dims: [512, 256]
  dropout_rate: 0.3
  use_batch_norm: true
  use_layer_norm: false
  activation: "relu"
  use_residual: false
  learning_rate: 0.001
  batch_size: 32
  max_epochs: 10
  early_stopping_patience: 20

threshold: .inf

task_name: EC
model_type: esm2
downstream_model:
  name: MLP

# Sweep parameters
sweep:
  learning_rate: [0.001, 0.01]
  batch_size: [32, 64]
  max_epochs: [50]
  hidden_dims: 
    - [256]
    - [512, 256]
  dropout_rate: [0.1, 0.25]
  use_batch_norm: [true, false]
  use_layer_norm: [true, false]
  activation: ["relu", "gelu"]
  use_residual: [true, false]
  model_type: [oneprot_16]
  task_name: ["HumanPPI", "MetalIonBinding", "EC", "GO-BP", "GO-MF", "GO-CC", "ThermoStability", "DeepLoc2", "DeepLoc10"] #[, "MetalIonBinding", "EC", "GO-BP", "GO-MF", "GO-CC", "ThermoStability", "DeepLoc2", "DeepLoc10"]
  
hydra:
  run:
    dir: ../outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}